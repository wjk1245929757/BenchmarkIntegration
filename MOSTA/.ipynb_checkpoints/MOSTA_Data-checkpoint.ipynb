{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe075d1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\bio\\DeepST\\DeepST-main2\\deepst\n",
      "D:\\bio\\DeepST\\DeepST-main2\\deepst\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "print(os.getcwd())#显示当前路径\n",
    "os.chdir('D:/bio/DeepST/DeepST-main2/deepst')#更改路径，''里面为更改的路径\n",
    "print(os.getcwd())#显示当前路径\n",
    "\n",
    "from DeepST import run\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from anndata import AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "367ec79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name_list = ['E9.5_E1S1', 'E10.5_E2S1', 'E11.5_E1S1', 'E12.5_E1S1']\n",
    "# data_path = '/home/lixiangyu/benchmark/data/MOSTA/'\n",
    "# save_path = '/home/lixiangyu/benchmark/data/MOSTA/STAligner/'\n",
    "# n_domains = 10\n",
    "\n",
    "data_path = 'G:/dataset/08-MOSTA/input/'\n",
    "save_path = 'G:/dataset/08-MOSTA/output/DeepST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cac9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepen = run(save_path = save_path, \n",
    "\ttask = \"Integration\",\n",
    "\tpre_epochs = 800, \n",
    "\tepochs = 1000, \n",
    "\tuse_gpu = True,\n",
    "\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e1e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from scipy.sparse import issparse,csr_matrix\n",
    "from sklearn.preprocessing import maxabs_scale, MaxAbsScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path, PurePath\n",
    "from typing import Optional, Union\n",
    "from anndata import AnnData\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "# import stlearn\n",
    "from _compat import Literal\n",
    "import scanpy\n",
    "import scipy\n",
    "\n",
    "\n",
    "def read_stereoSeq_h5ad(path,\n",
    "                bin_size=100,\n",
    "                is_sparse=True,\n",
    "                library_id=None,\n",
    "                scale=None,\n",
    "                quality=\"hires\",\n",
    "                spot_diameter_fullres=1,\n",
    "                background_color=\"white\",\n",
    "                ):\n",
    "    \n",
    "    adata = sc.read_h5ad(path)\n",
    "\n",
    "    if scale == None:\n",
    "        max_coor = np.max(adata.obsm[\"spatial\"])\n",
    "        scale = 20 / max_coor\n",
    "\n",
    "    adata.obs[\"imagecol\"] = adata.obsm[\"spatial\"][:, 0] * scale\n",
    "    adata.obs[\"imagerow\"] = adata.obsm[\"spatial\"][:, 1] * scale\n",
    "\n",
    "    # Create image\n",
    "    max_size = np.max([adata.obs[\"imagecol\"].max(), adata.obs[\"imagerow\"].max()])\n",
    "    max_size = int(max_size + 0.1 * max_size)\n",
    "    if background_color == \"black\":\n",
    "        image = Image.new(\"RGB\", (max_size, max_size), (0, 0, 0, 0))\n",
    "    else:\n",
    "        image = Image.new(\"RGB\", (max_size, max_size), (255, 255, 255, 255))\n",
    "    imgarr = np.array(image)\n",
    "\n",
    "    if library_id is None:\n",
    "        library_id = \"StereoSeq\"\n",
    "\n",
    "    adata.uns[\"spatial\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"][quality] = imgarr\n",
    "    adata.uns[\"spatial\"][library_id][\"use_quality\"] = quality\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"][\"tissue_\" + quality + \"_scalef\"] = scale\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"][\"spot_diameter_fullres\"] = spot_diameter_fullres\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E9.5_E1S1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tiling image: 100%|███████████████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extract image feature: 100%|██████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical distance calculting Done!\n",
      "The number of nearest tie neighbors in physical distance is: 30.0\n",
      "Gene correlation calculting Done!\n",
      "The weight result of image feature is added to adata.obsm['weights_matrix_all'] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find adjacent spots of each spot: 100%|███████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Augment molecule expression is Done!\n",
      "12.0000 neighbors per cell on average.\n",
      "Step 2: Graph computing is Done!\n",
      "E10.5_E2S1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tiling image: 100%|███████████████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extract image feature: 100%|██████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical distance calculting Done!\n",
      "The number of nearest tie neighbors in physical distance is: 30.0\n",
      "Gene correlation calculting Done!\n",
      "The weight result of image feature is added to adata.obsm['weights_matrix_all'] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find adjacent spots of each spot: 100%|███████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Augment molecule expression is Done!\n",
      "12.0000 neighbors per cell on average.\n",
      "Step 2: Graph computing is Done!\n",
      "E11.5_E1S1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tiling image: 100%|███████████████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extract image feature:  41%|████████████████████████████▍                                          [ time left: 31:19 ]"
     ]
    }
   ],
   "source": [
    "###### Generate an augmented list of multiple datasets\n",
    "augement_data_list = []\n",
    "graph_list = []\n",
    "for i in range(len(data_name_list)):\n",
    "\tprint(data_name_list[i])\n",
    "\tadata = read_stereoSeq_h5ad(path = os.path.join(data_path, data_name_list[i] + '.MOSTA.h5ad'))\n",
    "\t# adata = deepen._get_adata(platform=\"stereoSeq\", data_path=data_path, data_name=data_name_list[i])\n",
    "\tadata = deepen._get_image_crop(adata, data_name=data_name_list[i])\n",
    "\tadata = deepen._get_augment(adata, spatial_type=\"BallTree\", use_morphological=False)\n",
    "\tgraph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"BallTree\")\n",
    "        \n",
    "# \tsave_data_path = Path(os.path.join(save_path, \"Data\", data_name_list[i]))\n",
    "# \tsave_data_path.mkdir(parents=True, exist_ok=True)\n",
    "# \tadata.write(os.path.join(save_data_path, f'{data_name_list[i]}_raw.h5ad'), compression=\"gzip\")\n",
    "    \n",
    "\taugement_data_list.append(adata)\n",
    "\tgraph_list.append(graph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Synthetic Datasets and Graphs\n",
    "multiple_adata, multiple_graph = deepen._get_multiple_adata(adata_list = augement_data_list, data_name_list = data_name_list, graph_list = graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a29c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Enhanced data preprocessing\n",
    "data = deepen._data_process(multiple_adata, pca_n_comps = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1501d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepst_embed = deepen._fit(\n",
    "\t\tdata = data,\n",
    "\t\tgraph_dict = multiple_graph,\n",
    "\t\tdomains = multiple_adata.obs[\"batch\"].values,  ##### Input to Domain Adversarial Model\n",
    "\t\tn_domains = len(data_name_list))\n",
    "multiple_adata.obsm[\"DeepST_embed\"] = deepst_embed\n",
    "multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892ead58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(multiple_adata, use_rep='DeepST_embed')\n",
    "sc.tl.umap(multiple_adata)\n",
    "sc.pl.umap(multiple_adata, color=[\"DeepST_refine_domain\",\"batch_name\"])\n",
    "plt.savefig(os.path.join(save_path, f'{\"_\".join(data_name_list)}_umap.pdf'), bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a97fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_name in data_name_list:\n",
    "\tadata = multiple_adata[multiple_adata.obs[\"batch_name\"]==data_name]\n",
    "\tsc.pl.spatial(adata, color='DeepST_refine_domain', frameon = False, spot_size=150)\n",
    "\tplt.savefig(os.path.join(save_path, f'{data_name}_domains.pdf'), bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "print(multiple_adata.isbacked)\n",
    "multiple_adata.filename = save_path + '/MOSTA.h5ad'\n",
    "print(multiple_adata.isbacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff78018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook MOSTA_DeepST.ipynb to python\n",
      "[NbConvertApp] Writing 5267 bytes to MOSTA_DeepST.py\n"
     ]
    }
   ],
   "source": [
    "try:   \n",
    "    !jupyter nbconvert --to python MOSTA_DeepST.ipynb\n",
    "    # python即转化为.py，script即转化为.html\n",
    "    # file_name.ipynb即当前module的文件名\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepst",
   "language": "python",
   "name": "deepst_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
