{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe075d1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\bio\\jupyter_code\\MouseOlfactoryBulb\n",
      "D:\\bio\\DeepST\\DeepST-main2\\deepst\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "print(os.getcwd())#显示当前路径\n",
    "os.chdir('D:/bio/DeepST/DeepST-main2/deepst')#更改路径，''里面为更改的路径\n",
    "print(os.getcwd())#显示当前路径\n",
    "\n",
    "from DeepST import run\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from anndata import AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367ec79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"G:/dataset/06-Mouse olfactory bulb/input/25um/\" \n",
    "data_name_list = [\"10X\",\"slide\",\"stereo\"]\n",
    "save_path = \"G:/dataset/06-Mouse olfactory bulb/output/25um/DeepST\" \n",
    "n_domains = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3554f648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10X\n",
      "slide\n",
      "stereo\n"
     ]
    }
   ],
   "source": [
    "adata_list = []\n",
    "# meta = list()\n",
    "for dataset in data_name_list:\n",
    "\tprint(dataset)\n",
    "\tadata = sc.read_h5ad(data_path + dataset + '.h5ad')\n",
    "\tadata.var_names_make_unique()\n",
    "\tadata.obs_names_make_unique()\n",
    "\tdf = adata.obs[['x','y']].astype('float32')\n",
    "\tadata.obsm['spatial'] = df.values\n",
    "\tadata_list.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07aa2971-1f32-4535-96bf-a9acacc32b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Xkr4', 'Sox17', 'Rgs20', 'Npbwr1', 'St18', 'Sntg1', 'Cpa6',\n",
      "       'A830018L16Rik', 'Slco5a1', 'Msc',\n",
      "       ...\n",
      "       'Siah1b', 'Asb11', 'Glra2', 'Ofd1', 'Tceanc', 'Gm15232', 'Frmpd4',\n",
      "       'Mid1', 'Uty', 'Gm20835'],\n",
      "      dtype='object', length=3602)\n",
      "Index(['Xkr4', 'Sox17', 'Rgs20', 'Npbwr1', 'St18', 'Sntg1', 'Cpa6',\n",
      "       'A830018L16Rik', 'Slco5a1', 'Msc',\n",
      "       ...\n",
      "       'Siah1b', 'Asb11', 'Glra2', 'Ofd1', 'Tceanc', 'Gm15232', 'Frmpd4',\n",
      "       'Mid1', 'Uty', 'Gm20835'],\n",
      "      dtype='object', length=3602)\n",
      "AnnData object with n_obs × n_vars = 39076 × 3602\n",
      "    obs: 'orig.ident', 'nCount_Spatial', 'nFeature_Spatial', 'X', 'celltype', 'batch', 'row', 'col', 'x', 'y', 'imagerow', 'imagecol', 'batch_name', 'nCount_slide', 'nFeature_slide', 'nCount_stereo', 'nFeature_stereo'\n",
      "    var: 'features'\n",
      "    obsm: 'spatial'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_name_list)):\n",
    "    current_adata = adata_list[i]\n",
    "    current_adata.obs['batch_name'] = data_name_list[i]\n",
    "    current_adata.obs['batch_name'] = current_adata.obs['batch_name'].astype('category')\n",
    "    if i == 0:\n",
    "        multiple_adata = current_adata\n",
    "    else:\n",
    "        var_names = multiple_adata.var_names.intersection(current_adata.var_names)\n",
    "        print(var_names)\n",
    "        multiple_adata = multiple_adata[:, var_names]\n",
    "        current_adata = current_adata[:, var_names]\n",
    "        multiple_adata = multiple_adata.concatenate(current_adata)\n",
    "\n",
    "multiple_adata.obs[\"batch\"] = np.array(\n",
    "        pd.Categorical( multiple_adata.obs['batch_name'], categories=np.unique(multiple_adata.obs['batch_name'])).codes, dtype=np.int64, )\n",
    "\n",
    "print(multiple_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4d6043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepen = run(save_path = save_path, \n",
    "\ttask = \"Integration\",\n",
    "\tpre_epochs = 800, \n",
    "\tepochs = 1000, \n",
    "\tuse_gpu = True,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45e1e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from scipy.sparse import issparse,csr_matrix\n",
    "from sklearn.preprocessing import maxabs_scale, MaxAbsScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path, PurePath\n",
    "from typing import Optional, Union\n",
    "from anndata import AnnData\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "# import stlearn\n",
    "from _compat import Literal\n",
    "import scanpy\n",
    "import scipy\n",
    "\n",
    "def read_10X_Visium(path, \n",
    "                    genome = None,\n",
    "                    count_file ='filtered_feature_bc_matrix.h5', \n",
    "                    library_id = None, \n",
    "                    load_images =True, \n",
    "                    quality ='hires',\n",
    "                    image_path = None):\n",
    "    adata = sc.read_visium(path, \n",
    "                        genome = genome,\n",
    "                        count_file = count_file,\n",
    "                        library_id = library_id,\n",
    "                        load_images = load_images,\n",
    "                        )\n",
    "    adata.var_names_make_unique()\n",
    "    if library_id is None:\n",
    "        library_id = list(adata.uns[\"spatial\"].keys())[0]\n",
    "    if quality == \"fulres\":\n",
    "        image_coor = adata.obsm[\"spatial\"]\n",
    "        img = plt.imread(image_path, 0)\n",
    "        adata.uns[\"spatial\"][library_id][\"images\"][\"fulres\"] = img\n",
    "    else:\n",
    "        scale = adata.uns[\"spatial\"][library_id][\"scalefactors\"][\n",
    "            \"tissue_\" + quality + \"_scalef\"]\n",
    "        image_coor = adata.obsm[\"spatial\"] * scale\n",
    "    adata.obs[\"imagecol\"] = image_coor[:, 0]\n",
    "    adata.obs[\"imagerow\"] = image_coor[:, 1]\n",
    "    adata.uns[\"spatial\"][library_id][\"use_quality\"] = quality\n",
    "    return adata\n",
    "\n",
    "def read_SlideSeq(path, \n",
    "                 library_id = None,\n",
    "                 scale = None,\n",
    "                 quality = \"hires\",\n",
    "                 spot_diameter_fullres= 50,\n",
    "                 background_color = \"white\",):\n",
    "\n",
    "    count = pd.read_csv(os.path.join(path, \"count_matrix.count\"), sep='\\t', index_col=0)\n",
    "    meta = pd.read_csv(os.path.join(path, \"spatial.idx\"), index_col=0)\n",
    "\n",
    "    adata = AnnData(count.T)\n",
    "\n",
    "    # adata.var[\"ENSEMBL\"] = count[\"ENSEMBL\"].values\n",
    "\n",
    "    adata.obs[\"index\"] = meta[\"barcode\"].values\n",
    "\n",
    "    if scale == None:\n",
    "        max_coor = np.max(meta[[\"xcoord\", \"ycoord\"]].values)\n",
    "        scale = 2000 / max_coor\n",
    "\n",
    "    adata.obs[\"imagecol\"] = meta[\"xcoord\"].values * scale\n",
    "    adata.obs[\"imagerow\"] = meta[\"ycoord\"].values * scale\n",
    "\n",
    "    # Create image\n",
    "    max_size = np.max([adata.obs[\"imagecol\"].max(), adata.obs[\"imagerow\"].max()])\n",
    "    max_size = int(max_size + 0.1 * max_size)\n",
    "\n",
    "    if background_color == \"black\":\n",
    "        image = Image.new(\"RGBA\", (max_size, max_size), (0, 0, 0, 0))\n",
    "    else:\n",
    "        image = Image.new(\"RGBA\", (max_size, max_size), (255, 255, 255, 255))\n",
    "    imgarr = np.array(image)\n",
    "\n",
    "    if library_id is None:\n",
    "        library_id = \"Slide-seq\"\n",
    "\n",
    "    adata.uns[\"spatial\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"][quality] = imgarr\n",
    "    adata.uns[\"spatial\"][library_id][\"use_quality\"] = quality\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"][\n",
    "        \"tissue_\" + quality + \"_scalef\"] = scale\n",
    "\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"][\n",
    "        \"spot_diameter_fullres\"\n",
    "    ] = spot_diameter_fullres\n",
    "    adata.obsm[\"spatial\"] = meta[[\"xcoord\", \"ycoord\"]].values\n",
    "\n",
    "    return adata\n",
    "\n",
    "def read_stereoSeq(path,\n",
    "                bin_size=100,\n",
    "                is_sparse=True,\n",
    "                library_id=None,\n",
    "                scale=None,\n",
    "                quality=\"hires\",\n",
    "                spot_diameter_fullres=1,\n",
    "                background_color=\"white\",\n",
    "                ):\n",
    "    from scipy import sparse\n",
    "    count = pd.read_csv(os.path.join(path, \"count.txt\"), sep='\\t', comment='#', header=0)\n",
    "    count.dropna(inplace=True)\n",
    "    if \"MIDCounts\" in count.columns:\n",
    "        count.rename(columns={\"MIDCounts\": \"UMICount\"}, inplace=True)\n",
    "    count['x1'] = (count['x'] / bin_size).astype(np.int32)\n",
    "    count['y1'] = (count['y'] / bin_size).astype(np.int32)\n",
    "    count['pos'] = count['x1'].astype(str) + \"-\" + count['y1'].astype(str)\n",
    "    bin_data = count.groupby(['pos', 'geneID'])['UMICount'].sum()\n",
    "    cells = set(x[0] for x in bin_data.index)\n",
    "    genes = set(x[1] for x in bin_data.index)\n",
    "    cellsdic = dict(zip(cells, range(0, len(cells))))\n",
    "    genesdic = dict(zip(genes, range(0, len(genes))))\n",
    "    rows = [cellsdic[x[0]] for x in bin_data.index]\n",
    "    cols = [genesdic[x[1]] for x in bin_data.index]\n",
    "    exp_matrix = sparse.csr_matrix((bin_data.values, (rows, cols))) if is_sparse else \\\n",
    "                 sparse.csr_matrix((bin_data.values, (rows, cols))).toarray()\n",
    "    obs = pd.DataFrame(index=cells)\n",
    "    var = pd.DataFrame(index=genes)\n",
    "    adata = AnnData(X=exp_matrix, obs=obs, var=var)\n",
    "    pos = np.array(list(adata.obs.index.str.split('-', expand=True)), dtype=np.int)\n",
    "    adata.obsm['spatial'] = pos\n",
    "\n",
    "    if scale == None:\n",
    "        max_coor = np.max(adata.obsm[\"spatial\"])\n",
    "        scale = 20 / max_coor\n",
    "\n",
    "    adata.obs[\"imagecol\"] = adata.obsm[\"spatial\"][:, 0] * scale\n",
    "    adata.obs[\"imagerow\"] = adata.obsm[\"spatial\"][:, 1] * scale\n",
    "\n",
    "    # Create image\n",
    "    max_size = np.max([adata.obs[\"imagecol\"].max(), adata.obs[\"imagerow\"].max()])\n",
    "    max_size = int(max_size + 0.1 * max_size)\n",
    "    if background_color == \"black\":\n",
    "        image = Image.new(\"RGB\", (max_size, max_size), (0, 0, 0, 0))\n",
    "    else:\n",
    "        image = Image.new(\"RGB\", (max_size, max_size), (255, 255, 255, 255))\n",
    "    imgarr = np.array(image)\n",
    "\n",
    "    if library_id is None:\n",
    "        library_id = \"StereoSeq\"\n",
    "\n",
    "    adata.uns[\"spatial\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"][quality] = imgarr\n",
    "    adata.uns[\"spatial\"][library_id][\"use_quality\"] = quality\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"][\"tissue_\" + quality + \"_scalef\"] = scale\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"][\"spot_diameter_fullres\"] = spot_diameter_fullres\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e4c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "Tiling image: 100%|███████████████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extract image feature: 100%|██████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical distance calculting Done!\n",
      "The number of nearest tie neighbors in physical distance is: 1.0\n",
      "Gene correlation calculting Done!\n",
      "Morphological similarity calculting Done!\n",
      "The weight result of image feature is added to adata.obsm['weights_matrix_all'] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find adjacent spots of each spot: 100%|███████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Augment molecule expression is Done!\n",
      "12.0000 neighbors per cell on average.\n",
      "Step 2: Graph computing is Done!\n",
      "slide\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \t\tgraph_dict \u001b[38;5;241m=\u001b[39m deepen\u001b[38;5;241m.\u001b[39m_get_graph(adata\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatial\u001b[39m\u001b[38;5;124m\"\u001b[39m], distType \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBallTree\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m data_name_list[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslide\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 18\u001b[0m \t\tadata \u001b[38;5;241m=\u001b[39m \u001b[43mread_SlideSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_name_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# \t\tadata = deepen._get_adata(platform=\"slideSeq\", data_path=data_path, data_name=data_name_list[i])\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \t\tadata \u001b[38;5;241m=\u001b[39m deepen\u001b[38;5;241m.\u001b[39m_get_augment(adata, spatial_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBallTree\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_morphological\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 58\u001b[0m, in \u001b[0;36mread_SlideSeq\u001b[1;34m(path, library_id, scale, quality, spot_diameter_fullres, background_color)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_SlideSeq\u001b[39m(path, \n\u001b[0;32m     52\u001b[0m                  library_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     53\u001b[0m                  scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     54\u001b[0m                  quality \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhires\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m                  spot_diameter_fullres\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     56\u001b[0m                  background_color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m,):\n\u001b[1;32m---> 58\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcount_matrix.count\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     meta \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatial.idx\u001b[39m\u001b[38;5;124m\"\u001b[39m), index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     61\u001b[0m     adata \u001b[38;5;241m=\u001b[39m AnnData(count\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1055\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### Generate an augmented list of multiple datasets\n",
    "augement_data_list = []\n",
    "graph_list = []\n",
    "for i in range(len(data_name_list)):\n",
    "\tprint(data_name_list[i])\n",
    "\tif data_name_list[i] == \"10X\":\n",
    "\t\tadata = read_10X_Visium(path = os.path.join(data_path, data_name_list[i]))\n",
    "# \t\tadata = deepen._get_adata(platform=\"Visium\", data_path=data_path, data_name=data_name_list[i])\n",
    "\t\tadata = deepen._get_image_crop(adata, data_name=data_name_list[i])\n",
    "\t\tadata = deepen._get_augment(adata, spatial_type=\"LinearRegress\")\n",
    "\t\tgraph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"KDTree\")\n",
    "\tif data_name_list[i] == \"stereo\":\n",
    "\t\tadata = read_stereoSeq(path = os.path.join(data_path, data_name_list[i]))\n",
    "\t\tadata = deepen._get_adata(platform=\"stereoSeq\", data_path=data_path, data_name=data_name_list[i])\n",
    "\t\tadata = deepen._get_augment(adata, spatial_type=\"BallTree\", use_morphological=False)\n",
    "\t\tgraph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"BallTree\")\n",
    "\tif data_name_list[i] == \"slide\":\n",
    "\t\tadata = read_SlideSeq(path = os.path.join(data_path, data_name_list[i]))\n",
    "# \t\tadata = deepen._get_adata(platform=\"slideSeq\", data_path=data_path, data_name=data_name_list[i])\n",
    "\t\tadata = deepen._get_augment(adata, spatial_type=\"BallTree\", use_morphological=False)\n",
    "\t\tgraph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"BallTree\")\n",
    "        \n",
    "\tsave_data_path = Path(os.path.join(save_path, \"Data\", data_name_list[i]))\n",
    "\tsave_data_path.mkdir(parents=True, exist_ok=True)\n",
    "\tadata.write(os.path.join(save_data_path, f'{data_name_list[i]}_raw.h5ad'), compression=\"gzip\")\n",
    "    \n",
    "\taugement_data_list.append(adata)\n",
    "\tgraph_list.append(graph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Synthetic Datasets and Graphs\n",
    "multiple_adata, multiple_graph = deepen._get_multiple_adata(adata_list = augement_data_list, data_name_list = data_name_list, graph_list = graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a29c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Enhanced data preprocessing\n",
    "data = deepen._data_process(multiple_adata, pca_n_comps = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1501d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepst_embed = deepen._fit(\n",
    "\t\tdata = data,\n",
    "\t\tgraph_dict = multiple_graph,\n",
    "\t\tdomains = multiple_adata.obs[\"batch\"].values,  ##### Input to Domain Adversarial Model\n",
    "\t\tn_domains = len(data_name_list))\n",
    "multiple_adata.obsm[\"DeepST_embed\"] = deepst_embed\n",
    "multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892ead58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(multiple_adata, use_rep='DeepST_embed')\n",
    "sc.tl.umap(multiple_adata)\n",
    "sc.pl.umap(multiple_adata, color=[\"DeepST_refine_domain\",\"batch_name\"])\n",
    "plt.savefig(os.path.join(save_path, f'{\"_\".join(data_name_list)}_umap.pdf'), bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a97fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_name in data_name_list:\n",
    "\tadata = multiple_adata[multiple_adata.obs[\"batch_name\"]==data_name]\n",
    "\tsc.pl.spatial(adata, color='DeepST_refine_domain', frameon = False, spot_size=150)\n",
    "\tplt.savefig(os.path.join(save_path, f'{data_name}_domains.pdf'), bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "print(multiple_adata.isbacked)\n",
    "multiple_adata.filename = save_path + '/mouseOB.h5ad'\n",
    "print(multiple_adata.isbacked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepst",
   "language": "python",
   "name": "deepst_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
