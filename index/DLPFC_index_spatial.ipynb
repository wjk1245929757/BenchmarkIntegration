{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b75fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\bio\\jupyter_code\\index\n",
      "D:\\bio\\metirc\\scib-main\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())#显示当前路径\n",
    " \n",
    "os.chdir('D:/bio/metirc/scib-main')#更改路径，''里面为更改的路径\n",
    "\n",
    "print(os.getcwd())#显示当前路径\n",
    "\n",
    "os.environ['R_HOME'] = \"E:/R/R-4.2.1/\"\n",
    "os.environ['R_USER'] = \"D:/anaconda/envs/index/Lib/site-packages/rpy2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9485a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import index\n",
    "\n",
    "# import importlib\n",
    "# importlib.reload(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3ab2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scib\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad \n",
    "\n",
    "import esda\n",
    "from esda.moran import Moran, Moran_Local\n",
    "from esda.geary import Geary\n",
    "from esda.geary_local import Geary_Local\n",
    "from esda.getisord import G, G_Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81386d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(STUtility_coor_pd.shape)\n",
    "# print(adata_pre.obs_names[:5])\n",
    "# print(STUtility_coor_pd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "972ff557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4385943714739793\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "2.2665130327002347\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:185: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:186: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n",
      "D:\\bio\\metirc\\scib-main\\index\\spatial\\SSIM.py:36: RuntimeWarning: invalid value encountered in divide\n",
      "  im1, im2 = im1 / im1.max(), im2 / im2.max()\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:185: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:186: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n",
      "D:\\bio\\metirc\\scib-main\\index\\spatial\\SSIM.py:36: RuntimeWarning: invalid value encountered in divide\n",
      "  im1, im2 = im1 / im1.max(), im2 / im2.max()\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:185: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:186: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n",
      "D:\\bio\\metirc\\scib-main\\index\\spatial\\SSIM.py:36: RuntimeWarning: invalid value encountered in divide\n",
      "  im1, im2 = im1 / im1.max(), im2 / im2.max()\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:206: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:207: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:206: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:207: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:206: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:207: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ssim  slice  method\n",
      "0  0.943720      1  SPACEL\n",
      "1  0.906881      2  SPACEL\n",
      "2  0.918925      3  SPACEL\n",
      "        pcc  slice  method\n",
      "0  0.959204      1  SPACEL\n",
      "1  0.923520      2  SPACEL\n",
      "2  0.936749      3  SPACEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.380483607738061\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "2.336646571119643\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n",
      "1\n",
      "10\n",
      "50\n",
      "100\n",
      "500\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:185: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:186: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n",
      "D:\\bio\\metirc\\scib-main\\index\\spatial\\SSIM.py:36: RuntimeWarning: invalid value encountered in divide\n",
      "  im1, im2 = im1 / im1.max(), im2 / im2.max()\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:185: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:186: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n",
      "D:\\bio\\metirc\\scib-main\\index\\spatial\\SSIM.py:36: RuntimeWarning: invalid value encountered in divide\n",
      "  im1, im2 = im1 / im1.max(), im2 / im2.max()\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:185: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:186: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n",
      "D:\\bio\\metirc\\scib-main\\index\\spatial\\SSIM.py:36: RuntimeWarning: invalid value encountered in divide\n",
      "  im1, im2 = im1 / im1.max(), im2 / im2.max()\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:206: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:207: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:206: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:207: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:206: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_a = grid_a.loc[:, col]\n",
      "C:\\Users\\23147\\AppData\\Local\\Temp\\ipykernel_11440\\3181888351.py:207: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  grid_b = grid_b.loc[:, col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ssim  slice  method\n",
      "0  0.930609      1  SPIRAL\n",
      "1  0.913353      2  SPIRAL\n",
      "2  0.901520      3  SPIRAL\n",
      "        pcc  slice  method\n",
      "0  0.951667      1  SPIRAL\n",
      "1  0.932859      2  SPIRAL\n",
      "2  0.921592      3  SPIRAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "def load_data(start,end):\n",
    "    adata_list = []\n",
    "    for i in range(start,end):\n",
    "        input_dir = 'G:/dataset/1_DLPFC/input/'+str(i)+'/'\n",
    "        adata_temp = sc.read_visium(input_dir)\n",
    "        adata_temp.var_names_make_unique()\n",
    "        adata_temp.obs_names_make_unique()\n",
    "        adata_label = pd.read_csv(input_dir + 'truth.csv', index_col=0)\n",
    "        adata_temp.obs['batch'] = adata_label['batch'].astype(\"category\")\n",
    "        adata_temp.obs['ground.truth'] = adata_label['ground.truth'].astype(\"category\")\n",
    "        adata_list.append(adata_temp)\n",
    "    adata_pre = ad.concat(adata_list, index_unique=\"-\", keys = [i for i in range(start,end)])\n",
    "    return adata_pre\n",
    "\n",
    "\n",
    "methods = ['STUtility', 'moscot_affine', 'moscot_warp', 'STalign', 'paste', 'SPACEL', 'SPIRAL']\n",
    "\n",
    "for method in methods:\n",
    "    if method == 'STUtility':\n",
    "        continue\n",
    "        adata_pre = load_data(151673, 151677)\n",
    "        STUtility_coor_pd = pd.read_csv(\"G:/dataset/1_DLPFC/output/STUtility/Donor3-STutil-coords.csv\", sep=\" \")\n",
    "        STUtility_coord_list = []\n",
    "        STUtility_coor_pd.rename(index=lambda s: s.split('_',1)[0] + '-' + str(int(s.split('_',1)[1]) + 151672), inplace=True)\n",
    "        adatas = adata_pre[STUtility_coor_pd.index.tolist(), :]\n",
    "        adatas.obsm['spatial_aligned'] = STUtility_coor_pd[['align_x', 'align_y']].values\n",
    "        adatas.obsm['spatial_origin'] = STUtility_coor_pd[['x', 'y']].values\n",
    "    if method == 'moscot_affine':\n",
    "        continue\n",
    "        adata_pre = load_data(151673, 151677)\n",
    "        moscot_coor_pd = pd.read_csv(\"G:/dataset/1_DLPFC/output/moscot/moscot_affine_donor3.txt\", header = None)\n",
    "        adatas = adata_pre\n",
    "        adatas.obsm['spatial_aligned'] = moscot_coor_pd.values\n",
    "        adatas.obsm['spatial_origin'] = adatas.obsm['spatial'].copy()\n",
    "    if method == 'moscot_warp':\n",
    "        continue\n",
    "        adata_pre = load_data(151673, 151677)\n",
    "        moscot_coor_pd = pd.read_csv(\"G:/dataset/1_DLPFC/output/moscot/moscot_warp_donor3.txt\", header = None)\n",
    "        adatas = adata_pre\n",
    "        adatas.obsm['spatial_aligned'] = moscot_coor_pd.values\n",
    "        adatas.obsm['spatial_origin'] = adatas.obsm['spatial'].copy()\n",
    "    if method == 'STalign':\n",
    "        continue\n",
    "        adata_list = []\n",
    "        for i in range(151673, 151677):\n",
    "            input_dir = 'G:/dataset/1_DLPFC/input/'+str(i)+'/'\n",
    "            adata_temp = sc.read_visium(input_dir)\n",
    "            adata_temp.var_names_make_unique()\n",
    "            adata_temp.obs_names_make_unique()\n",
    "            adata_label = pd.read_csv(input_dir + 'truth.csv', index_col=0)\n",
    "            adata_temp.obs['batch'] = adata_label['batch'].astype(\"category\")\n",
    "            adata_temp.obs['ground.truth'] = adata_label['ground.truth'].astype(\"category\")\n",
    "            if i != 151676:\n",
    "                STalign_coor_pd = pd.read_csv('G:/dataset/1_DLPFC/output/STalign/'+str(i)+'_aligned_to_'+str(i+1)+'.csv')\n",
    "                STalign_coor_pd.index = STalign_coor_pd['0']\n",
    "                adata_temp.obsm['spatial_origin'] = adata_temp.obsm['spatial'].copy()\n",
    "                adata_temp.obsm['spatial_aligned'] = STalign_coor_pd[['aligned_y', 'aligned_x']].values\n",
    "            else:\n",
    "                adata_temp.obsm['spatial_origin'] = adata_temp.obsm['spatial'].copy()\n",
    "                adata_temp.obsm['spatial_aligned'] = adata_temp.obsm['spatial'].copy()\n",
    "            adata_list.append(adata_temp)\n",
    "        adata_pre = ad.concat(adata_list, index_unique=\"-\", keys = [i for i in range(151673,151677)])\n",
    "        adatas = adata_pre\n",
    "        del adata_list\n",
    "        del adata_temp\n",
    "    if method == 'paste':\n",
    "        continue\n",
    "        adata_list = []\n",
    "        for i in range(151673,151677):\n",
    "            input_dir = 'G:/dataset/1_DLPFC/input/'+str(i)+'/'\n",
    "            adata_temp = sc.read_visium(input_dir)\n",
    "            adata_temp.var_names_make_unique()\n",
    "            adata_temp.obs_names_make_unique()\n",
    "            adata_label = pd.read_csv(input_dir + 'truth.csv', index_col=0)\n",
    "            adata_temp.obs['batch'] = adata_label['batch'].astype(\"category\")\n",
    "            adata_temp.obs['ground.truth'] = adata_label['ground.truth'].astype(\"category\")\n",
    "            paste_coor_pd = pd.read_csv('G:/dataset/1_DLPFC/output/PASTE/'+str(i)+'.csv')\n",
    "            paste_coor_pd.index = paste_coor_pd['spot']\n",
    "            paste_coor_pd.rename(index=lambda s: s.split('.',1)[0], inplace=True)\n",
    "            adata_temp = adata_temp[paste_coor_pd.index.tolist(), :]\n",
    "            adata_temp.obsm['spatial_origin'] = adata_temp.obsm['spatial'].copy()\n",
    "            adata_temp.obsm['spatial_aligned'] = paste_coor_pd[['aligned_x', 'aligned_y']].values\n",
    "            adata_list.append(adata_temp)\n",
    "        adata_pre = ad.concat(adata_list, index_unique=\"-\", keys = [i for i in range(151673,151677)])\n",
    "        print(adata_pre)\n",
    "        adatas = adata_pre\n",
    "        del adata_temp\n",
    "        del adata_list\n",
    "    if method == 'SPACEL':\n",
    "        adata_pre = load_data(151673, 151677)\n",
    "        SPACEL_coor_pd = pd.read_csv(\"G:/dataset/1_DLPFC/output/SPACEL/donor3_aligned_coordinates.csv\")\n",
    "        adatas = adata_pre\n",
    "        adatas.obsm['spatial_aligned'] = SPACEL_coor_pd[['X','Y']].values\n",
    "        adatas.obsm['spatial_origin'] = adatas.obsm['spatial'].copy()\n",
    "    if method == 'SPIRAL':\n",
    "        adata_pre = load_data(151673, 151677)\n",
    "        SPIRAL_coor_pd = pd.read_csv(\"G:/dataset/1_DLPFC/output/SPIRAL/output/spiral/new_coord_151673_151674_151675_151676_modify.csv\")\n",
    "        SPIRAL_coor_pd.index = SPIRAL_coor_pd['Unnamed: 0']\n",
    "        SPIRAL_coor_pd.rename(index=lambda s: s.split('-',1)[1] + '-' + s.split('-',1)[0], inplace=True)\n",
    "        adatas = adata_pre[SPIRAL_coor_pd.index.tolist(), :]\n",
    "        adatas.obsm['spatial_aligned'] = SPIRAL_coor_pd[['x', 'y']].values\n",
    "        adatas.obsm['spatial_origin'] = adatas.obsm['spatial'].copy()\n",
    "        \n",
    "    ###SCC\n",
    "    # source\n",
    "    adatas.obsm['spatial'] = adatas.obsm['spatial_origin'].copy()\n",
    "    knn = 6\n",
    "    g, node_dict = index.generate_graph_from_labels(adatas, adatas.obs['ground.truth'] ,knn)\n",
    "    scs = index.spatial_coherence_score(g, node_dict, 100)\n",
    "    adatas.uns['scc_origin'] = scs\n",
    "    # align\n",
    "    adatas.obsm['spatial'] = adatas.obsm['spatial_aligned'].copy()\n",
    "    knn = 6\n",
    "    g, node_dict = index.generate_graph_from_labels(adatas, adatas.obs['ground.truth'] ,knn)\n",
    "    scs = index.spatial_coherence_score(g, node_dict, 100)\n",
    "    adatas.uns['scc_aligned'] = scs\n",
    "    \n",
    "    groups = adatas.obs.groupby(\"batch\").indices\n",
    "    adata_list = [adatas[i] for i in groups.values()]\n",
    "    \n",
    "    ###moran's I & geary's C\n",
    "    for i in range(4):\n",
    "        batch = list(groups.keys())[i].split('_')[1]\n",
    "        input_dir = 'G:/dataset/1_DLPFC/input/' + batch + '/'\n",
    "        SVGs = pd.read_csv(input_dir + 'SPARKX.csv', index_col=0)\n",
    "        SVGs = SVGs.sort_values(by=\"adjustedPval\",ascending=True)\n",
    "        # source\n",
    "        moranI_dict = {}\n",
    "        gearyC_dict = {}\n",
    "        sc.pp.neighbors(adata_list[i], use_rep='spatial_origin')\n",
    "        num = [1,10,50,100,500,1000]\n",
    "        for SVGnum in num:\n",
    "            print(SVGnum)\n",
    "            if SVGnum > SVGs.shape[0]:\n",
    "                break\n",
    "            moranI = np.mean( sc.metrics.morans_i(adata_list[i], vals = adata_list[i][:, SVGs.index.tolist()[:SVGnum]].X.toarray().T) )\n",
    "            moranI_dict[\"moranI_\"+str(SVGnum)] = moranI\n",
    "            gearyC = np.mean( sc.metrics.gearys_c(adata_list[i], vals = adata_list[i][:, SVGs.index.tolist()[:SVGnum]].X.toarray().T) )\n",
    "            gearyC_dict[\"gearyC_\"+str(SVGnum)] = gearyC\n",
    "        # align\n",
    "        moranI_align_dict = {}\n",
    "        gearyC_align_dict = {}\n",
    "        sc.pp.neighbors(adata_list[i], use_rep='spatial_aligned')\n",
    "        num = [1,10,50,100,500,1000]\n",
    "        for SVGnum in num:\n",
    "            print(SVGnum)\n",
    "            if SVGnum > SVGs.shape[0]:\n",
    "                break\n",
    "            moranI = np.mean( sc.metrics.morans_i(adata_list[i], vals = adata_list[i][:, SVGs.index.tolist()[:SVGnum]].X.toarray().T) )\n",
    "            moranI_align_dict[\"moranI_\"+str(SVGnum)] = moranI\n",
    "            gearyC = np.mean( sc.metrics.gearys_c(adata_list[i], vals = adata_list[i][:, SVGs.index.tolist()[:SVGnum]].X.toarray().T) )\n",
    "            gearyC_align_dict[\"gearyC_\"+str(SVGnum)] = gearyC\n",
    "        adata_list[i].uns['moranI'] = moranI_dict\n",
    "        adata_list[i].uns['moranI_align'] = moranI_align_dict\n",
    "        adata_list[i].uns['gearyC'] = gearyC_dict\n",
    "        adata_list[i].uns['gearyC_align'] = gearyC_align_dict\n",
    "    \n",
    "    ### SSIM & PCC\n",
    "    for i in range(len(adata_list)):\n",
    "        adata_list[i].obsm['spatial_aligned'] = pd.DataFrame(adata_list[i].obsm['spatial_aligned'], index=adata_list[i].obs_names)\n",
    "        adata_list[i].obsm['spatial_aligned'].columns = ['X', 'Y']\n",
    "    # each slice is rasterized on the overlap of the previous slice\n",
    "    for i in range(1, len(adata_list)):\n",
    "        x_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().X, adata_list[i - 1].obsm['spatial_aligned'].max().X]))\n",
    "        y_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().Y, adata_list[i - 1].obsm['spatial_aligned'].max().Y]))\n",
    "        x_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().X, adata_list[i - 1].obsm['spatial_aligned'].min().X]))\n",
    "        y_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().Y, adata_list[i - 1].obsm['spatial_aligned'].min().Y]))\n",
    "        adata_list[i].uns['grid_prop_withbefore'] = index.cal_grid_prop(adata_list[i], spatial_key='spatial_aligned', celltype_key='ground.truth',\n",
    "                                                             grid_max=[x_max, y_max], grid_min=[x_min, y_min])\n",
    "    # each slice is rasterized on the overlap of the next slice\n",
    "    for i in range(0, len(adata_list)-1):\n",
    "        x_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().X, adata_list[i + 1].obsm['spatial_aligned'].max().X]))\n",
    "        y_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().Y, adata_list[i + 1].obsm['spatial_aligned'].max().Y]))\n",
    "        x_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().X, adata_list[i + 1].obsm['spatial_aligned'].min().X]))\n",
    "        y_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().Y, adata_list[i + 1].obsm['spatial_aligned'].min().Y]))\n",
    "        adata_list[i].uns['grid_prop_withnext'] = index.cal_grid_prop(adata_list[i], spatial_key='spatial_aligned', celltype_key='ground.truth',\n",
    "                                                           grid_max=[x_max, y_max], grid_min=[x_min, y_min])\n",
    "    # calculate SSIM on the overlap of each two adjacent slices\n",
    "    for i in range(1, len(adata_list)):\n",
    "        grid_a = adata_list[i].uns['grid_prop_withbefore'].copy()\n",
    "        grid_b = adata_list[i - 1].uns['grid_prop_withnext'].copy()\n",
    "        col = set(grid_a.columns) & set(grid_b.columns)\n",
    "        grid_a = grid_a.loc[:, col]\n",
    "        grid_b = grid_b.loc[:, col]\n",
    "        ssim_list = []\n",
    "        for n in range(grid_a.shape[0]):\n",
    "            ssim_list.append(index.ssim(grid_a.iloc[n, :].values, grid_b.iloc[n, :].values))\n",
    "        ssim_list = np.array(ssim_list)\n",
    "        ssim_list[grid_b.sum(1) == 0] = np.inf\n",
    "        ssim_list[pd.isna(pd.Series(ssim_list))] = 0\n",
    "        adata_list[i].uns['ssim'] = ssim_list\n",
    "    ssim_compare = []\n",
    "    for i in range(1, len(adata_list)):\n",
    "        ssim_compare.append([adata_list[i].uns['ssim'][adata_list[i].uns['ssim'] != np.inf].mean(), i, method])\n",
    "    ssim_compare = pd.DataFrame(ssim_compare).fillna(0)\n",
    "    ssim_compare.columns = ['ssim', 'slice', 'method']\n",
    "    print(ssim_compare)\n",
    "    \n",
    "    # calculate PCC on the overlap of each two adjacent slices\n",
    "    for i in range(1, len(adata_list)):\n",
    "        grid_a = adata_list[i].uns['grid_prop_withbefore'].copy()\n",
    "        grid_b = adata_list[i - 1].uns['grid_prop_withnext'].copy()\n",
    "        col = set(grid_a.columns) & set(grid_b.columns)\n",
    "        grid_a = grid_a.loc[:, col]\n",
    "        grid_b = grid_b.loc[:, col]\n",
    "        pcc_list = []\n",
    "        for n in range(grid_a.shape[0]):\n",
    "            pcc_list.append(scipy.stats.pearsonr(grid_a.iloc[n, :].values, grid_b.iloc[n, :].values)[0])\n",
    "        pcc_list = np.array(pcc_list)\n",
    "        pcc_list[grid_b.sum(1) == 0] = np.inf\n",
    "        pcc_list[pd.isna(pd.Series(pcc_list))] = 0\n",
    "        adata_list[i].uns['pcc'] = pcc_list\n",
    "    pcc_compare = []\n",
    "    for i in range(1, len(adata_list)):\n",
    "        pcc_compare.append([adata_list[i].uns['pcc'][adata_list[i].uns['pcc'] != np.inf].mean(), i, method])\n",
    "    pcc_compare = pd.DataFrame(pcc_compare).fillna(0)\n",
    "    pcc_compare.columns = ['pcc', 'slice', 'method']\n",
    "    print(pcc_compare)\n",
    "    \n",
    "    \n",
    "    ### save\n",
    "    output_dir = 'G:/dataset/1_DLPFC/output/'\n",
    "    file = open(output_dir + 'Donor3_spatial_index.txt', 'a') \n",
    "    file.write('\\n')\n",
    "    file.write(method + ':\\n')\n",
    "    file.write('origin:' + str(adatas.uns['scc_origin']) +'\\n')\n",
    "    file.write('aligned:' + str(adatas.uns['scc_aligned']) + '\\n')\n",
    "    file.write('\\n')\n",
    "\n",
    "    for i in range(4):\n",
    "        batch = list(groups.keys())[i].split('_')[1]\n",
    "        for k,v in adata_list[i].uns['moranI'].items():\n",
    "            file.write(method +', moranI, '+str(k)+', '+str(v)+', '+batch+'\\n')\n",
    "        for k,v in adata_list[i].uns['moranI_align'].items():\n",
    "            file.write(method +', moranI_align, '+str(k)+', '+str(v)+', '+batch+'\\n')\n",
    "        for k,v in adata_list[i].uns['gearyC'].items():\n",
    "            file.write(method +', gearyC, '+str(k)+', '+str(v)+', '+batch+'\\n')\n",
    "        for k,v in adata_list[i].uns['gearyC_align'].items():\n",
    "            file.write(method +', gearyC_align, '+str(k)+', '+str(v)+', '+batch+'\\n')\n",
    "\n",
    "    file.write('\\n')\n",
    "    # 注意关闭文件\n",
    "    file.close()\n",
    "\n",
    "    ssim_compare.to_csv(output_dir + 'Donor3_spatial_index.txt',mode='a', index=True, header=True)\n",
    "    pcc_compare.to_csv(output_dir + 'Donor3_spatial_index.txt',mode='a', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c390780a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D2_151669': array([   0,    1,    2, ..., 3658, 3659, 3660], dtype=int64),\n",
       " 'D2_151670': array([3661, 3662, 3663, ..., 7156, 7157, 7158], dtype=int64),\n",
       " 'D2_151671': array([ 7159,  7160,  7161, ..., 11266, 11267, 11268], dtype=int64)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = adatas.obs.groupby(\"batch\").indices\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577ac883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 4226 × 33538\n",
      "    obs: 'in_tissue', 'array_row', 'array_col', 'batch', 'ground.truth'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'spatial'\n",
      "    obsm: 'spatial'\n",
      "151508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 4384 × 33538\n",
      "    obs: 'in_tissue', 'array_row', 'array_col', 'batch', 'ground.truth'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'spatial'\n",
      "    obsm: 'spatial'\n",
      "151509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 4789 × 33538\n",
      "    obs: 'in_tissue', 'array_row', 'array_col', 'batch', 'ground.truth'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'spatial'\n",
      "    obsm: 'spatial'\n",
      "151510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "D:\\anaconda\\envs\\index\\lib\\site-packages\\anndata\\_core\\anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 4634 × 33538\n",
      "    obs: 'in_tissue', 'array_row', 'array_col', 'batch', 'ground.truth'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'spatial'\n",
      "    obsm: 'spatial'\n",
      "AnnData object with n_obs × n_vars = 18033 × 33538\n",
      "    obs: 'in_tissue', 'array_row', 'array_col', 'batch', 'ground.truth'\n",
      "    obsm: 'spatial'\n"
     ]
    }
   ],
   "source": [
    "adata_list = []\n",
    "for i in range(151507,151511):\n",
    "    print(i)\n",
    "\n",
    "    input_dir = 'G:/dataset/1_DLPFC/input/'+str(i)+'/'  # Replace it with your file path\n",
    "\n",
    "    adata_temp = sc.read_visium(input_dir)\n",
    "    adata_temp.var_names_make_unique()\n",
    "    adata_temp.obs_names_make_unique()\n",
    "    adata_label = pd.read_csv(input_dir + 'truth.csv', index_col=0)\n",
    "    adata_temp.obs['batch'] = adata_label['batch'].astype(\"category\")\n",
    "    adata_temp.obs['ground.truth'] = adata_label['ground.truth'].astype(\"category\")\n",
    "    print(adata_temp)\n",
    "    adata_list.append(adata_temp)\n",
    "\n",
    "adata_pre = ad.concat(adata_list, index_unique=\"-\", keys = [i for i in range(151507,151511)])\n",
    "print(adata_pre)\n",
    "\n",
    "del adata_temp\n",
    "del adata_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada60b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'SPIRAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c5bd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # STUtility coor  (17889, 8)\n",
    "# STUtility_coor_pd = pd.read_csv(\"G:/dataset/1_DLPFC/output/STUtility/Donor1-STutil-coords.csv\", sep=\" \")\n",
    "# print(STUtility_coor_pd.shape)\n",
    "# print(STUtility_coor_pd.head())\n",
    "\n",
    "# STUtility_coord_list = []\n",
    "# STUtility_coor_pd.rename(index=lambda s: s.split('_',1)[0] + '-' + str(int(s.split('_',1)[1]) + 151506), inplace=True)\n",
    "\n",
    "# adatas = adata_pre[STUtility_coor_pd.index.tolist(), :]\n",
    "# adatas.obsm['spatial_aligned'] = STUtility_coor_pd[['align_x', 'align_y']].values\n",
    "# adatas.obsm['spatial_origin'] = STUtility_coor_pd[['x', 'y']].values\n",
    "# print(adatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc57f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # moscot  (18033, 2)\n",
    "# # moscot_coor_pd = pd.read_csv(\"G:/dataset/1_DLPFC/output/moscot/moscot_affine_donor1.txt\", header = None)\n",
    "# moscot_coor_pd = pd.read_csv(\"G:/dataset/1_DLPFC/output/moscot/moscot_warp_donor1.txt\", header = None)\n",
    "# print(moscot_coor_pd.shape)\n",
    "# print(moscot_coor_pd.head())\n",
    "\n",
    "# adatas = adata_pre\n",
    "\n",
    "# adatas.obsm['spatial_aligned'] = moscot_coor_pd.values\n",
    "# adatas.obsm['spatial_origin'] = adatas.obsm['spatial'].copy()\n",
    "\n",
    "# print(adatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b0975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # STalign \n",
    "# adata_list = []\n",
    "# for i in range(151507,151511):\n",
    "#     print(i)\n",
    "\n",
    "#     input_dir = 'G:/dataset/1_DLPFC/input/'+str(i)+'/'  # Replace it with your file path\n",
    "\n",
    "#     adata_temp = sc.read_visium(input_dir)\n",
    "#     adata_temp.var_names_make_unique()\n",
    "#     adata_temp.obs_names_make_unique()\n",
    "#     adata_label = pd.read_csv(input_dir + 'truth.csv', index_col=0)\n",
    "#     adata_temp.obs['batch'] = adata_label['batch'].astype(\"category\")\n",
    "#     adata_temp.obs['ground.truth'] = adata_label['ground.truth'].astype(\"category\")\n",
    "#     if i != 151510:\n",
    "#         STalign_coor_pd = pd.read_csv('G:/dataset/1_DLPFC/output/STalign/'+str(i)+'_aligned_to_'+str(i+1)+'.csv')\n",
    "#         STalign_coor_pd.index = STalign_coor_pd['0']\n",
    "#         adata_temp.obsm['spatial_origin'] = adata_temp.obsm['spatial'].copy()\n",
    "#         adata_temp.obsm['spatial_aligned'] = STalign_coor_pd[['aligned_y', 'aligned_x']].values\n",
    "#     else:\n",
    "#         adata_temp.obsm['spatial_origin'] = adata_temp.obsm['spatial'].copy()\n",
    "#         adata_temp.obsm['spatial_aligned'] = adata_temp.obsm['spatial'].copy()\n",
    "    \n",
    "#     print(adata_temp)\n",
    "#     adata_list.append(adata_temp)\n",
    "\n",
    "# adata_pre = ad.concat(adata_list, index_unique=\"-\", keys = [i for i in range(151507,151511)])\n",
    "# print(adata_pre)\n",
    "# adatas = adata_pre\n",
    "\n",
    "# del adata_temp\n",
    "# del adata_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aded3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # paste  17978 × 33538\n",
    "# adata_list = []\n",
    "# for i in range(151507,151511):\n",
    "#     print(i)\n",
    "\n",
    "#     input_dir = 'G:/dataset/1_DLPFC/input/'+str(i)+'/'  # Replace it with your file path\n",
    "\n",
    "#     adata_temp = sc.read_visium(input_dir)\n",
    "#     adata_temp.var_names_make_unique()\n",
    "#     adata_temp.obs_names_make_unique()\n",
    "#     adata_label = pd.read_csv(input_dir + 'truth.csv', index_col=0)\n",
    "#     adata_temp.obs['batch'] = adata_label['batch'].astype(\"category\")\n",
    "#     adata_temp.obs['ground.truth'] = adata_label['ground.truth'].astype(\"category\")\n",
    "    \n",
    "#     paste_coor_pd = pd.read_csv('G:/dataset/1_DLPFC/output/PASTE/'+str(i)+'.csv')\n",
    "#     paste_coor_pd.index = paste_coor_pd['spot']\n",
    "#     paste_coor_pd.rename(index=lambda s: s.split('.',1)[0], inplace=True)\n",
    "#     adata_temp = adata_temp[paste_coor_pd.index.tolist(), :]\n",
    "#     adata_temp.obsm['spatial_origin'] = adata_temp.obsm['spatial'].copy()\n",
    "#     adata_temp.obsm['spatial_aligned'] = paste_coor_pd[['aligned_x', 'aligned_y']].values\n",
    "    \n",
    "#     print(adata_temp)\n",
    "#     adata_list.append(adata_temp)\n",
    "\n",
    "# adata_pre = ad.concat(adata_list, index_unique=\"-\", keys = [i for i in range(151507,151511)])\n",
    "# print(adata_pre)\n",
    "# adatas = adata_pre\n",
    "\n",
    "# del adata_temp\n",
    "# del adata_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f972f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SPACEL  (18033, 3)\n",
    "# SPACEL_coor_pd = pd.read_csv(\"G:/dataset/1_DLPFC/output/SPACEL/donor1_aligned_coordinates.csv\")\n",
    "# print(SPACEL_coor_pd.shape)\n",
    "# print(SPACEL_coor_pd.head())\n",
    "\n",
    "# adatas = adata_pre\n",
    "\n",
    "# adatas.obsm['spatial_aligned'] = SPACEL_coor_pd[['X','Y']].values\n",
    "# adatas.obsm['spatial_origin'] = adatas.obsm['spatial'].copy()\n",
    "\n",
    "# print(adatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9138038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Unnamed: 0       x       y  clusters   batch\n",
      "0  151507-AAACAACGAATAGTTC-1  3276.0  2514.0         3  151507\n",
      "1  151507-AAACAAGTATCTCCCA-1  9178.0  8520.0         4  151507\n",
      "2  151507-AAACAATCTACTAGCA-1  5133.0  2878.0         3  151507\n",
      "3  151507-AAACACCAATAACTGC-1  3462.0  9581.0         6  151507\n",
      "4  151507-AAACAGCTTTCAGAAG-1  2779.0  7663.0         2  151507\n",
      "(17985, 5)\n",
      "Index(['AAACAACGAATAGTTC-1-151507', 'AAACAAGTATCTCCCA-1-151507',\n",
      "       'AAACAATCTACTAGCA-1-151507', 'AAACACCAATAACTGC-1-151507',\n",
      "       'AAACAGCTTTCAGAAG-1-151507'],\n",
      "      dtype='object')\n",
      "                                          Unnamed: 0       x       y  \\\n",
      "Unnamed: 0                                                             \n",
      "AAACAACGAATAGTTC-1-151507  151507-AAACAACGAATAGTTC-1  3276.0  2514.0   \n",
      "AAACAAGTATCTCCCA-1-151507  151507-AAACAAGTATCTCCCA-1  9178.0  8520.0   \n",
      "AAACAATCTACTAGCA-1-151507  151507-AAACAATCTACTAGCA-1  5133.0  2878.0   \n",
      "AAACACCAATAACTGC-1-151507  151507-AAACACCAATAACTGC-1  3462.0  9581.0   \n",
      "AAACAGCTTTCAGAAG-1-151507  151507-AAACAGCTTTCAGAAG-1  2779.0  7663.0   \n",
      "\n",
      "                           clusters   batch  \n",
      "Unnamed: 0                                   \n",
      "AAACAACGAATAGTTC-1-151507         3  151507  \n",
      "AAACAAGTATCTCCCA-1-151507         4  151507  \n",
      "AAACAATCTACTAGCA-1-151507         3  151507  \n",
      "AAACACCAATAACTGC-1-151507         6  151507  \n",
      "AAACAGCTTTCAGAAG-1-151507         2  151507  \n",
      "AnnData object with n_obs × n_vars = 17985 × 33538\n",
      "    obs: 'in_tissue', 'array_row', 'array_col', 'batch', 'ground.truth'\n",
      "    obsm: 'spatial', 'spatial_aligned', 'spatial_origin'\n"
     ]
    }
   ],
   "source": [
    "SPIRAL_coor_pd = pd.read_csv(\"G:/dataset/1_DLPFC/output/SPIRAL/output/spiral/new_coord_151507_151508_151509_151510_modify.csv\")\n",
    "print(SPIRAL_coor_pd.head())\n",
    "print(SPIRAL_coor_pd.shape)\n",
    "print(adata_pre.obs_names[:5])\n",
    "\n",
    "SPIRAL_coor_pd.index = SPIRAL_coor_pd['Unnamed: 0']\n",
    "SPIRAL_coor_pd.rename(index=lambda s: s.split('-',1)[1] + '-' + s.split('-',1)[0], inplace=True)\n",
    "print(SPIRAL_coor_pd.head())\n",
    "\n",
    "adatas = adata_pre[SPIRAL_coor_pd.index.tolist(), :]\n",
    "\n",
    "adatas.obsm['spatial_aligned'] = SPIRAL_coor_pd[['x', 'y']].values\n",
    "adatas.obsm['spatial_origin'] = adatas.obsm['spatial'].copy()\n",
    "print(adatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d2187",
   "metadata": {},
   "source": [
    "# Pre Exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ddf8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17985, 2)\n",
      "(17985, 2)\n",
      "[[ 3276  2514]\n",
      " [ 9178  8520]\n",
      " [ 5133  2878]\n",
      " ...\n",
      " [ 3514  5649]\n",
      " [10564  6907]\n",
      " [10289  6664]]\n",
      "[[ 3276.          2514.        ]\n",
      " [ 9178.          8520.        ]\n",
      " [ 5133.          2878.        ]\n",
      " ...\n",
      " [ 4315.25287356  3235.56704981]\n",
      " [10671.57471264  3790.93103448]\n",
      " [10363.          3613.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(adatas.obsm['spatial_origin'].shape)\n",
    "print(adatas.obsm['spatial_aligned'].shape)\n",
    "print(adatas.obsm['spatial_origin'])\n",
    "print(adatas.obsm['spatial_aligned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652abbd",
   "metadata": {},
   "source": [
    "# SCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6014e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# source\n",
    "adatas.obsm['spatial'] = adatas.obsm['spatial_origin'].copy()\n",
    "knn = 6\n",
    "g, node_dict = index.generate_graph_from_labels(adatas, adatas.obs['ground.truth'] ,knn)\n",
    "scs = index.spatial_coherence_score(g, node_dict, 100)\n",
    "adatas.uns['scc_origin'] = scs\n",
    "print(scs)\n",
    "\n",
    "# align\n",
    "adatas.obsm['spatial'] = adatas.obsm['spatial_aligned'].copy()\n",
    "knn = 6\n",
    "g, node_dict = index.generate_graph_from_labels(adatas, adatas.obs['ground.truth'] ,knn)\n",
    "scs = index.spatial_coherence_score(g, node_dict, 100)\n",
    "adatas.uns['scc_aligned'] = scs\n",
    "print(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cea730",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab9f01",
   "metadata": {},
   "source": [
    "# Moran's I & Geary's C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a6e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups = adatas.obs.groupby(\"batch\").indices\n",
    "adata_list = [adatas[i] for i in groups.values()]\n",
    "\n",
    "for i in range(4):\n",
    "    batch = list(groups.keys())[i].split('_')[1]\n",
    "    print(batch)\n",
    "    input_dir = 'G:/dataset/1_DLPFC/input/' + batch + '/'\n",
    "    SVGs = pd.read_csv(input_dir + 'SPARKX.csv', index_col=0)\n",
    "    print(SVGs.shape)\n",
    "    SVGs = SVGs.sort_values(by=\"adjustedPval\",ascending=True)\n",
    "    \n",
    "    # source\n",
    "    moranI_dict = {}\n",
    "    gearyC_dict = {}\n",
    "    sc.pp.neighbors(adata_list[i], use_rep='spatial_origin')\n",
    "    num = [1,10,50,100,500,1000]\n",
    "    for SVGnum in num:\n",
    "        print(SVGnum)\n",
    "        if SVGnum > SVGs.shape[0]:\n",
    "            break\n",
    "        moranI = np.mean( sc.metrics.morans_i(adata_list[i], vals = adata_list[i][:, SVGs.index.tolist()[:SVGnum]].X.toarray().T) )\n",
    "        moranI_dict[\"moranI_\"+str(SVGnum)] = moranI\n",
    "        gearyC = np.mean( sc.metrics.gearys_c(adata_list[i], vals = adata_list[i][:, SVGs.index.tolist()[:SVGnum]].X.toarray().T) )\n",
    "        gearyC_dict[\"gearyC_\"+str(SVGnum)] = gearyC\n",
    "        \n",
    "    # align\n",
    "    moranI_align_dict = {}\n",
    "    gearyC_align_dict = {}\n",
    "    sc.pp.neighbors(adata_list[i], use_rep='spatial_aligned')\n",
    "    num = [1,10,50,100,500,1000]\n",
    "    for SVGnum in num:\n",
    "        print(SVGnum)\n",
    "        if SVGnum > SVGs.shape[0]:\n",
    "            break\n",
    "        moranI = np.mean( sc.metrics.morans_i(adata_list[i], vals = adata_list[i][:, SVGs.index.tolist()[:SVGnum]].X.toarray().T) )\n",
    "        moranI_align_dict[\"moranI_\"+str(SVGnum)] = moranI\n",
    "        gearyC = np.mean( sc.metrics.gearys_c(adata_list[i], vals = adata_list[i][:, SVGs.index.tolist()[:SVGnum]].X.toarray().T) )\n",
    "        gearyC_align_dict[\"gearyC_\"+str(SVGnum)] = gearyC\n",
    "        \n",
    "    adata_list[i].uns['moranI'] = moranI_dict\n",
    "    adata_list[i].uns['moranI_align'] = moranI_align_dict\n",
    "    adata_list[i].uns['gearyC'] = gearyC_dict\n",
    "    adata_list[i].uns['gearyC_align'] = gearyC_align_dict\n",
    "    print(adata_list[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1707b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    batch = list(groups.keys())[i].split('_')[1]\n",
    "    print(batch)\n",
    "    print('moranI')\n",
    "    print(adata_list[i].uns['moranI'])\n",
    "    print('moranI_align')\n",
    "    print(adata_list[i].uns['moranI_align'])\n",
    "    print('gearyC')\n",
    "    print(adata_list[i].uns['gearyC'])\n",
    "    print('gearyC_align')\n",
    "    print(adata_list[i].uns['gearyC_align'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c7de0",
   "metadata": {},
   "source": [
    "# SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c3b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = adatas.obs.groupby(\"batch\").indices\n",
    "adata_list = [adatas[i] for i in groups.values()]\n",
    "\n",
    "for i in range(len(adata_list)):\n",
    "    adata_list[i].obsm['spatial_aligned'] = pd.DataFrame(adata_list[i].obsm['spatial_aligned'], index=adata_list[i].obs_names)\n",
    "    adata_list[i].obsm['spatial_aligned'].columns = ['X', 'Y']\n",
    "\n",
    "# each slice is rasterized on the overlap of the previous slice\n",
    "for i in range(1, len(adata_list)):\n",
    "    x_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().X, adata_list[i - 1].obsm['spatial_aligned'].max().X]))\n",
    "    y_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().Y, adata_list[i - 1].obsm['spatial_aligned'].max().Y]))\n",
    "    x_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().X, adata_list[i - 1].obsm['spatial_aligned'].min().X]))\n",
    "    y_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().Y, adata_list[i - 1].obsm['spatial_aligned'].min().Y]))\n",
    "    adata_list[i].uns['grid_prop_withbefore'] = index.cal_grid_prop(adata_list[i], spatial_key='spatial_aligned', celltype_key='ground.truth',\n",
    "                                                         grid_max=[x_max, y_max], grid_min=[x_min, y_min])\n",
    "\n",
    "# each slice is rasterized on the overlap of the next slice\n",
    "for i in range(0, len(adata_list)-1):\n",
    "    x_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().X, adata_list[i + 1].obsm['spatial_aligned'].max().X]))\n",
    "    y_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().Y, adata_list[i + 1].obsm['spatial_aligned'].max().Y]))\n",
    "    x_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().X, adata_list[i + 1].obsm['spatial_aligned'].min().X]))\n",
    "    y_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().Y, adata_list[i + 1].obsm['spatial_aligned'].min().Y]))\n",
    "    adata_list[i].uns['grid_prop_withnext'] = index.cal_grid_prop(adata_list[i], spatial_key='spatial_aligned', celltype_key='ground.truth',\n",
    "                                                       grid_max=[x_max, y_max], grid_min=[x_min, y_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db00fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Layer 1   Layer 2   Layer 3   Layer 4   Layer 5   Layer 6   WM\n",
      "0   0.100000  0.100000  0.800000  0.000000  0.000000  0.000000  0.0\n",
      "1   0.115385  0.134615  0.711538  0.000000  0.019231  0.019231  0.0\n",
      "2   0.345455  0.109091  0.163636  0.000000  0.072727  0.309091  0.0\n",
      "3   0.000000  0.000000  0.609756  0.073171  0.048780  0.268293  0.0\n",
      "4   0.000000  0.000000  0.187500  0.500000  0.281250  0.031250  0.0\n",
      "..       ...       ...       ...       ...       ...       ...  ...\n",
      "95  0.032258  0.322581  0.645161  0.000000  0.000000  0.000000  0.0\n",
      "96  0.000000  0.058824  0.941176  0.000000  0.000000  0.000000  0.0\n",
      "97  0.000000  0.052632  0.947368  0.000000  0.000000  0.000000  0.0\n",
      "98  0.000000  0.285714  0.714286  0.000000  0.000000  0.000000  0.0\n",
      "99  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0\n",
      "\n",
      "[100 rows x 7 columns]\n",
      "     Layer 1   Layer 2   Layer 3   Layer 4   Layer 5   Layer 6   WM\n",
      "0   0.111111  0.000000  0.888889  0.000000  0.000000  0.000000  0.0\n",
      "1   0.102041  0.163265  0.734694  0.000000  0.000000  0.000000  0.0\n",
      "2   0.568182  0.181818  0.250000  0.000000  0.000000  0.000000  0.0\n",
      "3   0.121212  0.000000  0.787879  0.060606  0.000000  0.030303  0.0\n",
      "4   0.000000  0.000000  0.216216  0.378378  0.351351  0.054054  0.0\n",
      "..       ...       ...       ...       ...       ...       ...  ...\n",
      "95  0.000000  0.419355  0.580645  0.000000  0.000000  0.000000  0.0\n",
      "96  0.000000  0.166667  0.833333  0.000000  0.000000  0.000000  0.0\n",
      "97  0.000000  0.000000  0.894737  0.000000  0.105263  0.000000  0.0\n",
      "98  0.000000  0.000000  0.461538  0.076923  0.461538  0.000000  0.0\n",
      "99  0.000000  0.000000  1.000000  0.000000  0.000000  0.000000  0.0\n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(adata_list[2].uns['grid_prop_withnext'])\n",
    "print(adata_list[3].uns['grid_prop_withbefore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33612231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate SSIM on the overlap of each two adjacent slices\n",
    "for i in range(1, len(adata_list)):\n",
    "    grid_a = adata_list[i].uns['grid_prop_withbefore'].copy()\n",
    "    grid_b = adata_list[i - 1].uns['grid_prop_withnext'].copy()\n",
    "    col = set(grid_a.columns) & set(grid_b.columns)\n",
    "    grid_a = grid_a.loc[:, col]\n",
    "    grid_b = grid_b.loc[:, col]\n",
    "    ssim_list = []\n",
    "    for n in range(grid_a.shape[0]):\n",
    "        ssim_list.append(index.ssim(grid_a.iloc[n, :].values, grid_b.iloc[n, :].values))\n",
    "    ssim_list = np.array(ssim_list)\n",
    "    ssim_list[grid_b.sum(1) == 0] = np.inf\n",
    "    ssim_list[pd.isna(pd.Series(ssim_list))] = 0\n",
    "    adata_list[i].uns['ssim'] = ssim_list\n",
    "\n",
    "ssim_compare = []\n",
    "for i in range(1, len(adata_list)):\n",
    "    ssim_compare.append([adata_list[i].uns['ssim'][adata_list[i].uns['ssim'] != np.inf].mean(), i, method])\n",
    "    # ssim_compare.append([paste[i].uns['ssim'][paste[i].uns['ssim'] != np.inf].mean(), i, 'paste'])\n",
    "\n",
    "ssim_compare = pd.DataFrame(ssim_compare).fillna(0)\n",
    "ssim_compare.columns = ['ssim', 'slice', 'method']\n",
    "# ssim_compare.to_csv('G:/dataset/1_DLPFC/output/ssim_compare_donor1.csv')\n",
    "print(ssim_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cfe336",
   "metadata": {},
   "source": [
    "# PCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c400a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "# groups = adatas.obs.groupby(\"batch\").indices\n",
    "# adata_list = [adatas[i] for i in groups.values()]\n",
    "\n",
    "for i in range(len(adata_list)):\n",
    "    adata_list[i].obsm['spatial_aligned'] = pd.DataFrame(adata_list[i].obsm['spatial_aligned'], index=adata_list[i].obs_names)\n",
    "    adata_list[i].obsm['spatial_aligned'].columns = ['X', 'Y']\n",
    "\n",
    "# each slice is rasterized on the overlap of the previous slice\n",
    "for i in range(1, len(adata_list)):\n",
    "    x_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().X, adata_list[i - 1].obsm['spatial_aligned'].max().X]))\n",
    "    y_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().Y, adata_list[i - 1].obsm['spatial_aligned'].max().Y]))\n",
    "    x_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().X, adata_list[i - 1].obsm['spatial_aligned'].min().X]))\n",
    "    y_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().Y, adata_list[i - 1].obsm['spatial_aligned'].min().Y]))\n",
    "    adata_list[i].uns['grid_prop_withbefore'] = index.cal_grid_prop(adata_list[i], spatial_key='spatial_aligned', celltype_key='ground.truth',\n",
    "                                                         grid_max=[x_max, y_max], grid_min=[x_min, y_min])\n",
    "\n",
    "# each slice is rasterized on the overlap of the next slice\n",
    "for i in range(0, len(adata_list)-1):\n",
    "    x_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().X, adata_list[i + 1].obsm['spatial_aligned'].max().X]))\n",
    "    y_max = np.ceil(np.min([adata_list[i].obsm['spatial_aligned'].max().Y, adata_list[i + 1].obsm['spatial_aligned'].max().Y]))\n",
    "    x_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().X, adata_list[i + 1].obsm['spatial_aligned'].min().X]))\n",
    "    y_min = np.floor(np.max([adata_list[i].obsm['spatial_aligned'].min().Y, adata_list[i + 1].obsm['spatial_aligned'].min().Y]))\n",
    "    adata_list[i].uns['grid_prop_withnext'] = index.cal_grid_prop(adata_list[i], spatial_key='spatial_aligned', celltype_key='ground.truth',\n",
    "                                                       grid_max=[x_max, y_max], grid_min=[x_min, y_min])\n",
    "    \n",
    "# calculate PCC on the overlap of each two adjacent slices\n",
    "for i in range(1, len(adata_list)):\n",
    "    grid_a = adata_list[i].uns['grid_prop_withbefore'].copy()\n",
    "    grid_b = adata_list[i - 1].uns['grid_prop_withnext'].copy()\n",
    "    col = set(grid_a.columns) & set(grid_b.columns)\n",
    "    grid_a = grid_a.loc[:, col]\n",
    "    grid_b = grid_b.loc[:, col]\n",
    "    pcc_list = []\n",
    "    for n in range(grid_a.shape[0]):\n",
    "        pcc_list.append(scipy.stats.pearsonr(grid_a.iloc[n, :].values, grid_b.iloc[n, :].values)[0])\n",
    "    pcc_list = np.array(pcc_list)\n",
    "    pcc_list[grid_b.sum(1) == 0] = np.inf\n",
    "    pcc_list[pd.isna(pd.Series(pcc_list))] = 0\n",
    "    adata_list[i].uns['pcc'] = pcc_list\n",
    "\n",
    "pcc_compare = []\n",
    "for i in range(1, len(adata_list)):\n",
    "    pcc_compare.append([adata_list[i].uns['pcc'][adata_list[i].uns['pcc'] != np.inf].mean(), i, method])\n",
    "    # ssim_compare.append([adata_list[i].uns['ssim'][adata_list[i].uns['ssim'] != np.inf].mean(), i, 'STUtility'])\n",
    "\n",
    "pcc_compare = pd.DataFrame(pcc_compare).fillna(0)\n",
    "pcc_compare.columns = ['pcc', 'slice', 'method']\n",
    "print(pcc_compare)\n",
    "# pcc_compare.to_csv('G:/dataset/1_DLPFC/output/pcc_compare_donor1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea983b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'G:/dataset/1_DLPFC/output/'\n",
    "file = open(output_dir + 'Donor1_spatial_index.txt', 'a') \n",
    "\n",
    "file.write(method + ':\\n')\n",
    "file.write('origin:' + str(adatas.uns['scc_origin']) +'\\n')\n",
    "file.write('aligned:' + str(adatas.uns['scc_aligned']) + '\\n')\n",
    "file.write('\\n')\n",
    "\n",
    "for i in range(4):\n",
    "    batch = list(groups.keys())[i].split('_')[1]\n",
    "    for k,v in adata_list[i].uns['moranI'].items():\n",
    "        file.write(method +', moranI, '+str(k)+', '+str(v)+', '+batch+'\\n')\n",
    "    for k,v in adata_list[i].uns['moranI_align'].items():\n",
    "        file.write(method +', moranI_align, '+str(k)+', '+str(v)+', '+batch+'\\n')\n",
    "    for k,v in adata_list[i].uns['gearyC'].items():\n",
    "        file.write(method +', gearyC, '+str(k)+', '+str(v)+', '+batch+'\\n')\n",
    "    for k,v in adata_list[i].uns['gearyC_align'].items():\n",
    "        file.write(method +', gearyC_align, '+str(k)+', '+str(v)+', '+batch+'\\n')\n",
    "    \n",
    "file.write('\\n')\n",
    "# 注意关闭文件\n",
    "file.close()\n",
    "\n",
    "ssim_compare.to_csv(output_dir + 'Donor1_spatial_index.txt',mode='a', index=True, header=True)\n",
    "pcc_compare.to_csv(output_dir + 'Donor1_spatial_index.txt',mode='a', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "index",
   "language": "python",
   "name": "index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
