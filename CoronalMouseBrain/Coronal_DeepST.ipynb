{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8d1bd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\bio\\DeepST\\DeepST-main2\\deepst\n",
      "D:\\bio\\DeepST\\DeepST-main2\\deepst\n",
      "10X_DAPI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "Tiling image: 100%|███████████████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extract image feature: 100%|██████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical distance calculting Done!\n",
      "The number of nearest tie neighbors in physical distance is: 32.73406820530486\n",
      "Gene correlation calculting Done!\n",
      "Morphological similarity calculting Done!\n",
      "The weight result of image feature is added to adata.obsm['weights_matrix_all'] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find adjacent spots of each spot: 100%|███████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Augment molecule expression is Done!\n",
      "12.0000 neighbors per cell on average.\n",
      "Step 2: Graph computing is Done!\n",
      "10X_FFPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "Tiling image: 100%|███████████████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extract image feature: 100%|██████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical distance calculting Done!\n",
      "The number of nearest tie neighbors in physical distance is: 6.819787985865724\n",
      "Gene correlation calculting Done!\n",
      "Morphological similarity calculting Done!\n",
      "The weight result of image feature is added to adata.obsm['weights_matrix_all'] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find adjacent spots of each spot: 100%|███████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Augment molecule expression is Done!\n",
      "12.0000 neighbors per cell on average.\n",
      "Step 2: Graph computing is Done!\n",
      "10X_Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "Tiling image: 100%|███████████████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extract image feature: 100%|██████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical distance calculting Done!\n",
      "The number of nearest tie neighbors in physical distance is: 33.08438193930422\n",
      "Gene correlation calculting Done!\n",
      "Morphological similarity calculting Done!\n",
      "The weight result of image feature is added to adata.obsm['weights_matrix_all'] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find adjacent spots of each spot: 100%|███████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Augment molecule expression is Done!\n",
      "12.0000 neighbors per cell on average.\n",
      "Step 2: Graph computing is Done!\n",
      "single adata OK!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple adata OK!\n",
      "Enhanced data preprocessing\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.14 GiB for an array with shape (7869, 19465) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m###### Enhanced data preprocessing\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnhanced data preprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdeepen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmultiple_adata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpca_n_comps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m deepst_embed \u001b[38;5;241m=\u001b[39m deepen\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m     81\u001b[0m \t\tdata \u001b[38;5;241m=\u001b[39m data,\n\u001b[0;32m     82\u001b[0m \t\tgraph_dict \u001b[38;5;241m=\u001b[39m multiple_graph,\n\u001b[0;32m     83\u001b[0m \t\tdomains \u001b[38;5;241m=\u001b[39m multiple_adata\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,  \u001b[38;5;66;03m##### Input to Domain Adversarial Model\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \t\tn_domains \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_name_list))\n\u001b[0;32m     85\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepst_embedding.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), deepst_embed, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\bio\\DeepST\\DeepST-main2\\deepst\\DeepST.py:202\u001b[0m, in \u001b[0;36mrun._data_process\u001b[1;34m(self, adata, pca_n_comps)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_data_process\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    198\u001b[0m \tadata,\n\u001b[0;32m    199\u001b[0m \tpca_n_comps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m    200\u001b[0m \t):\n\u001b[0;32m    201\u001b[0m \tadata\u001b[38;5;241m.\u001b[39mraw \u001b[38;5;241m=\u001b[39m adata\n\u001b[1;32m--> 202\u001b[0m \tadata\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m \u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobsm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maugment_gene_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \tdata \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mpp\u001b[38;5;241m.\u001b[39mnormalize_total(adata, target_sum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    204\u001b[0m \tdata \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mpp\u001b[38;5;241m.\u001b[39mlog1p(data)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.14 GiB for an array with shape (7869, 19465) and data type float64"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os \n",
    "\n",
    "print(os.getcwd())#显示当前路径\n",
    "os.chdir('D:/bio/DeepST/DeepST-main2/deepst')#更改路径，''里面为更改的路径\n",
    "print(os.getcwd())#显示当前路径\n",
    "\n",
    "from DeepST import run\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from anndata import AnnData\n",
    "\n",
    "\n",
    "data_name_list = ['10X_DAPI', '10X_FFPE', '10X_Normal']\n",
    "data_path = 'G:/dataset/05-CoronalMouseBrain/input/'\n",
    "save_path = 'G:/dataset/05-CoronalMouseBrain/output/DeepST/'\n",
    "\n",
    "\n",
    "deepen = run(save_path = save_path, \n",
    "\ttask = \"Integration\",\n",
    "\tpre_epochs = 800, \n",
    "\tepochs = 1000, \n",
    "\tuse_gpu = True,\n",
    "\t)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from scipy.sparse import issparse,csr_matrix\n",
    "from sklearn.preprocessing import maxabs_scale, MaxAbsScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path, PurePath\n",
    "from typing import Optional, Union\n",
    "from anndata import AnnData\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "# import stlearn\n",
    "from _compat import Literal\n",
    "import scanpy\n",
    "import scipy\n",
    "\n",
    "from matplotlib.image import imread\n",
    "import json\n",
    "\n",
    "\n",
    "###### Generate an augmented list of multiple datasets\n",
    "augement_data_list = []\n",
    "graph_list = []\n",
    "from scipy.sparse import csr_matrix\n",
    "for i in range(len(data_name_list)):\n",
    "\tprint(data_name_list[i])\n",
    "\tadata = deepen._get_adata(platform=\"Visium\", data_path=data_path, data_name=data_name_list[i])\n",
    "\tadata = deepen._get_image_crop(adata, data_name=data_name_list[i])\n",
    "\tadata = deepen._get_augment(adata, spatial_type=\"LinearRegress\")\n",
    "\tgraph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"KDTree\")\n",
    "\taugement_data_list.append(adata)\n",
    "\tgraph_list.append(graph_dict)\n",
    "\n",
    "print('single adata OK!')\n",
    "\n",
    "######## Synthetic Datasets and Graphs\n",
    "multiple_adata, multiple_graph = deepen._get_multiple_adata(adata_list = augement_data_list, data_name_list = data_name_list, graph_list = graph_list)\n",
    "\n",
    "print('multiple adata OK!')\n",
    "###### Enhanced data preprocessing\n",
    "print('Enhanced data preprocessing')\n",
    "data = deepen._data_process(multiple_adata, pca_n_comps = 200)\n",
    "\n",
    "\n",
    "deepst_embed = deepen._fit(\n",
    "\t\tdata = data,\n",
    "\t\tgraph_dict = multiple_graph,\n",
    "\t\tdomains = multiple_adata.obs[\"batch\"].values,  ##### Input to Domain Adversarial Model\n",
    "\t\tn_domains = len(data_name_list))\n",
    "np.savetxt(os.path.join(save_path, \"deepst_embedding.csv\"), deepst_embed, delimiter=\",\")\n",
    "\n",
    "n_domains = 6\n",
    "\n",
    "multiple_adata.obsm[\"DeepST_embed\"] = deepst_embed\n",
    "multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "\n",
    "\n",
    "sc.pp.neighbors(multiple_adata, use_rep='DeepST_embed')\n",
    "sc.tl.umap(multiple_adata)\n",
    "sc.pl.umap(multiple_adata, color=[\"DeepST_refine_domain\",\"batch_name\"])\n",
    "plt.savefig(os.path.join(save_path, f'{\"_\".join(data_name_list)}_umap.pdf'), bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "for data_name in data_name_list:\n",
    "\tadata = multiple_adata[multiple_adata.obs[\"batch_name\"]==data_name]\n",
    "\tsc.pl.spatial(adata, color='DeepST_refine_domain', frameon = False, spot_size=150)\n",
    "\tplt.savefig(os.path.join(save_path, f'{data_name}_domains.pdf'), bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "print(multiple_adata.isbacked)\n",
    "multiple_adata.filename = save_path + '/PDAC.h5ad'\n",
    "print(multiple_adata.isbacked)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepst",
   "language": "python",
   "name": "deepst_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
