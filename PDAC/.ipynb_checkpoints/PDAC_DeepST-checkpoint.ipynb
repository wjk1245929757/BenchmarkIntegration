{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6daf34c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\bio\\jupyter_code\\PDAC\n",
      "D:\\bio\\DeepST\\DeepST-main2\\deepst\n",
      "A1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tiling image: 100%|███████████████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extract image feature: 100%|██████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical distance calculting Done!\n",
      "The number of nearest tie neighbors in physical distance is: 30.0\n",
      "Gene correlation calculting Done!\n",
      "The weight result of image feature is added to adata.obsm['weights_matrix_all'] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find adjacent spots of each spot: 100%|███████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Augment molecule expression is Done!\n",
      "12.0000 neighbors per cell on average.\n",
      "Step 2: Graph computing is Done!\n",
      "B1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tiling image: 100%|███████████████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extract image feature: 100%|██████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical distance calculting Done!\n",
      "The number of nearest tie neighbors in physical distance is: 30.0\n",
      "Gene correlation calculting Done!\n",
      "The weight result of image feature is added to adata.obsm['weights_matrix_all'] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find adjacent spots of each spot: 100%|███████████████████████████████████████████████████████████ [ time left: 00:00 ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Augment molecule expression is Done!\n",
      "12.0000 neighbors per cell on average.\n",
      "Step 2: Graph computing is Done!\n",
      "single adata OK!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\anndata\\_core\\anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple adata OK!\n",
      "Enhanced data preprocessing\n",
      "Your task is in full swing, please wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepST trains an initial model: 100%|█████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "DeepST trains a final model:   0%|                                                                     [ time left: ? ]D:\\anaconda\\envs\\deepst_env\\lib\\site-packages\\torch\\nn\\functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "DeepST trains a final model: |                                                                     [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: DeepST training has been Done!\n",
      "Current memory usage：3.5143 GB\n",
      "Total time: 2.52 minutes\n",
      "Your task has been completed, thank you\n",
      "Of course, you can also perform downstream analysis on the processed data\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_domains' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 169\u001b[0m\n\u001b[0;32m    167\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepst_embedding.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), deepst_embed, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    168\u001b[0m multiple_adata\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepST_embed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m deepst_embed\n\u001b[1;32m--> 169\u001b[0m multiple_adata \u001b[38;5;241m=\u001b[39m deepen\u001b[38;5;241m.\u001b[39m_get_cluster_data(multiple_adata, n_domains\u001b[38;5;241m=\u001b[39m\u001b[43mn_domains\u001b[49m, priori \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    172\u001b[0m sc\u001b[38;5;241m.\u001b[39mpp\u001b[38;5;241m.\u001b[39mneighbors(multiple_adata, use_rep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepST_embed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    173\u001b[0m sc\u001b[38;5;241m.\u001b[39mtl\u001b[38;5;241m.\u001b[39mumap(multiple_adata)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_domains' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os \n",
    "\n",
    "print(os.getcwd())#显示当前路径\n",
    "os.chdir('D:/bio/DeepST/DeepST-main2/deepst')#更改路径，''里面为更改的路径\n",
    "print(os.getcwd())#显示当前路径\n",
    "\n",
    "from DeepST import run\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from anndata import AnnData\n",
    "\n",
    "\n",
    "data_name_list = ['A1', 'B1']\n",
    "data_path = 'G:/dataset/04-PDAC/input/'\n",
    "save_path = 'G:/dataset/04-PDAC/output/'\n",
    "\n",
    "\n",
    "deepen = run(save_path = save_path, \n",
    "\ttask = \"Integration\",\n",
    "\tpre_epochs = 800, \n",
    "\tepochs = 1000, \n",
    "\tuse_gpu = False,\n",
    "\t)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from scipy.sparse import issparse,csr_matrix\n",
    "from sklearn.preprocessing import maxabs_scale, MaxAbsScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path, PurePath\n",
    "from typing import Optional, Union\n",
    "from anndata import AnnData\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "# import stlearn\n",
    "from _compat import Literal\n",
    "import scanpy\n",
    "import scipy\n",
    "\n",
    "from matplotlib.image import imread\n",
    "import json\n",
    "\n",
    "def create_image(path,\n",
    "                is_sparse=True,\n",
    "                library_id=None,\n",
    "                scale=None,\n",
    "                quality=\"hires\",\n",
    "                spot_diameter_fullres=1,\n",
    "                background_color=\"white\",\n",
    "                ):\n",
    "    \n",
    "    adata = sc.read_h5ad(path)\n",
    "    adata.obsm['spatial'] = adata.obs[['x', 'y']].values\n",
    "    adata.obsm['spatial'] = adata.obsm['spatial'].astype(float)\n",
    "    if scale == None:\n",
    "        max_coor = np.max(adata.obsm[\"spatial\"])\n",
    "        scale = 20 / max_coor\n",
    "\n",
    "    adata.obs[\"imagecol\"] = adata.obsm[\"spatial\"][:, 0] * scale\n",
    "    adata.obs[\"imagerow\"] = adata.obsm[\"spatial\"][:, 1] * scale\n",
    "\n",
    "    # Create image\n",
    "    max_size = np.max([adata.obs[\"imagecol\"].max(), adata.obs[\"imagerow\"].max()])\n",
    "    max_size = int(max_size + 0.1 * max_size)\n",
    "    if background_color == \"black\":\n",
    "        image = Image.new(\"RGB\", (max_size, max_size), (0, 0, 0, 0))\n",
    "    else:\n",
    "        image = Image.new(\"RGB\", (max_size, max_size), (255, 255, 255, 255))\n",
    "    imgarr = np.array(image)\n",
    "\n",
    "    if library_id is None:\n",
    "        library_id = \"MERFISH\"\n",
    "\n",
    "    adata.uns[\"spatial\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"][quality] = imgarr\n",
    "    adata.uns[\"spatial\"][library_id][\"use_quality\"] = quality\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"][\"tissue_\" + quality + \"_scalef\"] = scale\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"][\"spot_diameter_fullres\"] = spot_diameter_fullres\n",
    "\n",
    "    return adata\n",
    "\n",
    "def add_visium_image(\n",
    "    adata,\n",
    "    path,\n",
    "    scale=None,\n",
    "    library_id = None,\n",
    "    load_images = True,\n",
    "    source_image_path = None,\n",
    "    quality =\"fulres\",\n",
    "    spot_diameter_fullres=1\n",
    ") -> AnnData:\n",
    "    \n",
    "    path = Path(path)\n",
    "\n",
    "    from h5py import File\n",
    "    if library_id is None:\n",
    "        library_id = 'deepst'\n",
    "        \n",
    "    image_path = path / 'pic_low_quality.jpg'\n",
    "    img = plt.imread(image_path)\n",
    "    \n",
    "    if scale == None:\n",
    "        max_coor = np.max(adata.obsm[\"spatial\"])\n",
    "        scale = 20 / max_coor\n",
    "    \n",
    "    adata.obs[\"imagecol\"] = adata.obsm[\"spatial\"][:, 0] * scale\n",
    "    adata.obs[\"imagerow\"] = adata.obsm[\"spatial\"][:, 1] * scale\n",
    "    \n",
    "    adata.uns[\"spatial\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"][quality] = img\n",
    "    adata.uns[\"spatial\"][library_id][\"use_quality\"] = quality\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"] = {}\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"][\"tissue_\" + quality + \"_scalef\"] = scale\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"][\"spot_diameter_fullres\"] = spot_diameter_fullres\n",
    "    return adata\n",
    "\n",
    "\n",
    "###### Generate an augmented list of multiple datasets\n",
    "augement_data_list = []\n",
    "graph_list = []\n",
    "from scipy.sparse import csr_matrix\n",
    "for i in range(len(data_name_list)):\n",
    "\tprint(data_name_list[i])\n",
    "\tadata = sc.read_h5ad(data_path + data_name_list[i] + '/' + data_name_list[i] +'.h5ad')\n",
    "\tadata.obsm['spatial'] = adata.obs[['x', 'y']].values\n",
    "\tadata.obsm['spatial'] = adata.obsm['spatial'].astype(float)\n",
    "\tadata = add_visium_image(adata, data_path + data_name_list[i])\n",
    "\tadata = deepen._get_image_crop(adata, data_name=data_name_list[i])\n",
    "\tadata = deepen._get_augment(adata, spatial_type=\"BallTree\", use_morphological=False)\n",
    "\tgraph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"BallTree\")\n",
    "\taugement_data_list.append(adata)\n",
    "\tgraph_list.append(graph_dict)\n",
    "\n",
    "print('single adata OK!')\n",
    "\n",
    "######## Synthetic Datasets and Graphs\n",
    "multiple_adata, multiple_graph = deepen._get_multiple_adata(adata_list = augement_data_list, data_name_list = data_name_list, graph_list = graph_list)\n",
    "\n",
    "print('multiple adata OK!')\n",
    "###### Enhanced data preprocessing\n",
    "print('Enhanced data preprocessing')\n",
    "data = deepen._data_process(multiple_adata, pca_n_comps = 200)\n",
    "\n",
    "\n",
    "deepst_embed = deepen._fit(\n",
    "\t\tdata = data,\n",
    "\t\tgraph_dict = multiple_graph,\n",
    "\t\tdomains = multiple_adata.obs[\"batch\"].values,  ##### Input to Domain Adversarial Model\n",
    "\t\tn_domains = len(data_name_list))\n",
    "np.savetxt(os.path.join(save_path, \"deepst_embedding.csv\"), deepst_embed, delimiter=\",\")\n",
    "multiple_adata.obsm[\"DeepST_embed\"] = deepst_embed\n",
    "multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "\n",
    "\n",
    "sc.pp.neighbors(multiple_adata, use_rep='DeepST_embed')\n",
    "sc.tl.umap(multiple_adata)\n",
    "sc.pl.umap(multiple_adata, color=[\"DeepST_refine_domain\",\"batch_name\"])\n",
    "plt.savefig(os.path.join(save_path, f'{\"_\".join(data_name_list)}_umap.pdf'), bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "for data_name in data_name_list:\n",
    "\tadata = multiple_adata[multiple_adata.obs[\"batch_name\"]==data_name]\n",
    "\tsc.pl.spatial(adata, color='DeepST_refine_domain', frameon = False, spot_size=150)\n",
    "\tplt.savefig(os.path.join(save_path, f'{data_name}_domains.pdf'), bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "print(multiple_adata.isbacked)\n",
    "multiple_adata.filename = save_path + '/PDAC.h5ad'\n",
    "print(multiple_adata.isbacked)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepst",
   "language": "python",
   "name": "deepst_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
